# Proyecto covid19DF â€“ EvaluaciÃ³n Pipelines y DAGs

[![Powered by Kedro](https://img.shields.io/badge/powered_by-kedro-ffc900?logo=kedro)](https://kedro.org)

Sistema MLOps modular para anÃ¡lisis de datos de COVIDâ€‘19 con pipelines de **regresiÃ³n**, **clasificaciÃ³n**, **reducciÃ³n de dimensionalidad (PCA + tâ€‘SNE)** y **clustering (Kâ€‘Means, JerÃ¡rquico, GMM)**, orquestados mediante **Apache Airflow** y versionados con **DVC**.

---
## ğŸ“‹ Tabla de Contenidos
1. [CaracterÃ­sticas](#caracterÃ­sticas)
2. [Arquitectura](#arquitectura)
3. [Requisitos](#requisitos)
4. [InstalaciÃ³n](#instalaciÃ³n)
5. [Estructura de Carpetas](#estructura-de-carpetas)
6. [Datasets y CatÃ¡logo](#datasets-y-catÃ¡logo)
7. [ParÃ¡metros Clave](#parÃ¡metros-clave)
8. [Pipelines y DAGs](#pipelines-y-dags)
9. [EjecuciÃ³n Local (Kedro)](#ejecuciÃ³n-local-kedro)
10. [OrquestaciÃ³n con Airflow](#orquestaciÃ³n-con-airflow)
11. [Versionamiento con DVC](#versionamiento-con-dvc)
12. [MÃ©tricas y Resultados Esperados](#mÃ©tricas-y-resultados-esperados)
13. [Reproducibilidad Completa](#reproducibilidad-completa)
14. [Buenas PrÃ¡cticas](#buenas-prÃ¡cticas)
15. [Troubleshooting](#troubleshooting)
16. [CrÃ©ditos](#crÃ©ditos)

---
## ğŸŒŸ CaracterÃ­sticas
- Pipelines modulares con Kedro (lazy registry + aliases).
- DAGs de Airflow para ejecuciÃ³n automatizada:
  - `regresion_dag.py`
  - `clasificacion_dag.py`
  - `reduccion_dimensional_dag.py`
  - `kmeans_dag.py`, `jerarquico_dag.py`, `gmm_dag.py`
- ReducciÃ³n de dimensionalidad: PCA (varianza explicada, loadings, biplot) + tâ€‘SNE (2D/3D, subsampling controlado).
- Clustering mÃºltiple con mÃ©tricas de validaciÃ³n:
  - Kâ€‘Means (inertia + Elbow + silhouette, Daviesâ€‘Bouldin, Calinskiâ€‘Harabasz)
  - JerÃ¡rquico (Ward + dendrograma truncado + mÃ©tricas)
  - Gaussian Mixture (GMM con probabilidades, BIC/AIC + mÃ©tricas)
- Visualizaciones generadas y persistidas (PNG) parametrizadas vÃ­a `MatplotlibDataset`.
- Submuestreo controlado para evitar OOM en tâ€‘SNE, JerÃ¡rquico y GMM.
- Versionamiento de outputs con DVC (stages declarados en `dvc.yaml`).
- Logging enriquecido en nodos para inspecciÃ³n rÃ¡pida en CLI y Airflow.

---
## ğŸ— Arquitectura
```
covid19df/
  airflow/dags/        # DAGs de orquestaciÃ³n
  conf/base/           # catalog.yml, parameters.yml (global)
  conf/local/          # overrides locales (no versionar en remoto)
  data/                # 01_raw, 03_intermediate, 05_train (artefactos)
  src/covid19df/       # cÃ³digo fuente (pipeline_registry, pipelines/*)
  dvc.yaml             # definiciÃ³n de stages reproducibles
  dvc.lock             # lock de dependencias/outs
  .dvc/                # cache y configuraciÃ³n DVC
```

---
## ğŸ§© Requisitos
- Python >= 3.10
- Kedro >= 0.19
- scikit-learn, pandas, numpy, matplotlib
- DVC >= 2.x
- Apache Airflow (opcional para DAGs)
- Docker (si se desea orquestaciÃ³n aislada)

---
## âš¡ InstalaciÃ³n
```powershell
git clone <URL_DEL_REPO>
cd covid19df
python -m venv venv_kedro
./venv_kedro/Scripts/Activate.ps1
pip install -r requirements.txt
```

Opcional inicializar DVC (ya existente):
```powershell
dvc status
```

---
## ğŸ—‚ Estructura de Carpetas
- `data/01_raw/`: datos crudos.
- `data/03_intermediate/`: features y embeddings (PCA, tâ€‘SNE, X_features_*).
- `data/05_train/`: resultados finales (labels, mÃ©tricas, plots, comparaciones).
- `conf/base/parameters.yml`: parÃ¡metros globales de todos los pipelines.
- `src/covid19df/pipelines/*`: definiciÃ³n de nodos y wiring.
- `airflow/dags/*.py`: definiciÃ³n de cada DAG.

---
## ğŸ“¦ Datasets y CatÃ¡logo
`conf/base/catalog.yml` registra entradas y salidas: CSVDataset, MatplotlibDataset, Pickle y JSON. Plots usan `save_args` para controlar `dpi` y bounding box.

---
## ğŸ”§ ParÃ¡metros Clave
Fragmentos relevantes (simplificado):
```yaml
reduccion_dimensional:
  n_pca_components: 10
  tsne_perplexity: 30
  tsne_n_iter: 1000
  tsne_max_samples_2d: 2000
  tsne_max_samples_3d: 1000
  tsne_enable_3d: true

kmeans:
  kmeans_n_clusters: 5
  kmeans_elbow_min_k: 2
  kmeans_elbow_max_k: 10

jerarquico:
  jerarquico_n_clusters: 5
  jerarquico_linkage: ward
  jerarquico_max_samples: 3000

gmm:
  gmm_n_components: 5
  gmm_covariance_type: full
  gmm_max_samples: 5000
  gmm_reg_covar: 1e-6
```

---
## ğŸ§ª Pipelines y DAGs
| Pipeline | DAG | PropÃ³sito | Principales Outputs |
|----------|-----|-----------|---------------------|
| regresion | `regresion_dag.py` | Modelos continuos comparativos | `regression_comparison.csv/png` |
| clasificacion | `clasificacion_dag.py` | ComparaciÃ³n de clasificadores | `classification_comparison.csv/png` |
| reduccion_dimensional | `reduccion_dimensional_dag.py` | PCA + tâ€‘SNE 2D/3D | `pca_*`, `tsne_embeddings_*`, plots PCA/TSNE |
| kmeans | `kmeans_dag.py` | Clustering Kâ€‘Means + Elbow + mÃ©tricas | `kmeans_labels.csv`, `kmeans_metrics.csv`, `kmeans_elbow.png`, `kmeans_plot.png` |
| jerarquico | `jerarquico_dag.py` | Clustering jerÃ¡rquico + dendrograma | `jerarquico_labels.csv`, `jerarquico_metrics.csv`, `jerarquico_dendrogram.png`, `jerarquico_plot.png` |
| gmm | `gmm_dag.py` | Mezcla Gaussiana probabilÃ­stica | `gmm_labels.csv`, `gmm_metrics.csv`, `gmm_plot.png` |

---
## â–¶ï¸ EjecuciÃ³n Local (Kedro)
Ejecutar un pipeline especÃ­fico:
```powershell
./venv_kedro/Scripts/Activate.ps1
kedro run --pipeline reduccion_dimensional
kedro run --pipeline kmeans
kedro run --pipeline jerarquico
kedro run --pipeline gmm
```
Ejecutar todos:
```powershell
kedro run
```

---
## â˜ OrquestaciÃ³n con Airflow
1. Construir imagen (si se usa Dockerfile en `airflow/`):
```powershell
docker compose -f airflow/docker-compose.yaml up -d --build
```
2. Acceder a UI Airflow, activar DAGs: `regresion_dag`, `clasificacion_dag`, `reduccion_dimensional_dag`, `kmeans_dag`, `jerarquico_dag`, `gmm_dag`.
3. Cada DAG ejecuta `kedro run --pipeline <nombre>` dentro del contenedor.

Logs Ãºtiles: se imprimen muestras de features y mÃ©tricas en cada nodo (`logger.info`).

---
## ğŸ” Versionamiento con DVC
Stages declarados en `dvc.yaml` para: `kmeans_run`, `jerarquico_run`, `gmm_run` (y se pueden ampliar).
Reproducir:
```powershell
dvc repro kmeans_run
dvc repro jerarquico_run
dvc repro gmm_run
```
Subir a remote (definir previamente):
```powershell
dvc push
git add dvc.yaml dvc.lock
git commit -m "Actualiza stages DVC"
git push origin main
```

---
## ğŸ“ˆ MÃ©tricas y Resultados Esperados
Clustering:
- Silhouette (â‰ˆ 0 a 1): mÃ¡s alto mejor separaciÃ³n.
- Daviesâ€‘Bouldin: menor es mejor.
- Calinskiâ€‘Harabasz: mayor es mejor.
- Elbow (Kâ€‘Means): buscar el punto de inflexiÃ³n de `inertia`.
- Dendrograma (JerÃ¡rquico): cortes horizontales sugieren nÃºmero de clusters potencial.
- GMM: usar BIC/AIC (mÃ¡s bajos mejor) y probabilidades altas para confianza.

ReducciÃ³n de dimensionalidad:
- PCA: revisar `pca_explained_variance.csv` y biplot para componentes relevantes.
- tâ€‘SNE: embeddings 2D/3D para estructura local; subsampling reduce tiempos.

RegresiÃ³n / ClasificaciÃ³n: archivos `*_comparison.csv/png` con ranking por mÃ©trica (RMSE, accuracy, etc.).

InterpretaciÃ³n rÃ¡pida:
- Si un mÃ©todo produce un cluster masivo y muchos mÃ­nimos, considerar normalizar previo al fit (ya se estandariza para mÃ©tricas/plots) o ajustar hiperparÃ¡metros.
- Si silhouette < 0.1: clusters poco Ãºtiles; revisar k o cambiar algoritmo.

---
## â™»ï¸ Reproducibilidad Completa
1. Clonar repositorio y crear entorno.
2. `dvc pull` (si se comparte remote) para obtener artefactos.
3. `kedro run --pipeline <pipeline>` o `dvc repro <stage>` para regenerar outputs.
4. Comparar cambios con `dvc diff` antes de hacer push.

---
## âœ… Buenas PrÃ¡cticas
- Mantener datos crudos inmutables en `data/01_raw/`.
- Usar parÃ¡metros en `conf/local/` para ejecuciones rÃ¡pidas (submuestreo) sin modificar base.
- Versionar sÃ³lo artefactos finales vÃ­a DVC stages (no subir binarios grandes a Git).
- Revisar logs de nodos para validaciones rÃ¡pidas sin abrir archivos.
- AÃ±adir nuevas mÃ©tricas en nodos separados para no romper reproducibilidad.

---
## ğŸ›  Troubleshooting
| Problema | Causa | SoluciÃ³n |
|----------|-------|----------|
| `ValueError` GMM covarianza | Singularidad | Incrementar `gmm_reg_covar` o reducir `gmm_n_components` |
| tâ€‘SNE muy lento | Demasiadas filas | Bajar `tsne_max_samples_*` o `tsne_n_iter` |
| JerÃ¡rquico OOM | Complejidad O(n^2) | Ajustar `jerarquico_max_samples` |
| MÃ©tricas NaN | 1 solo cluster | Ajustar k / parÃ¡metros para generar mÃ¡s de un cluster |
| DVC conflicto outs | Doble tracking | Ejecutar `dvc remove <.dvc>` y usar stage en `dvc.yaml` |

---
## ğŸ‘¤ CrÃ©ditos
Autor: Hans Ignacio Mancilla Sandoval  
Contacto: ha.mancilla@duocuc.cl  
Asignatura: Machine Learning  
Profesor: Giocrisrai Godoy  

---
## ğŸ“„ Licencia
Proyecto acadÃ©mico; uso educativo y demostrativo.

---
## ğŸ” Referencias
- Kedro Docs: https://docs.kedro.org
- DVC Docs: https://dvc.org/doc
- scikit-learn Cluster Metrics: https://scikit-learn.org/stable/modules/clustering.html

---
## ğŸš€ Comandos RÃ¡pidos
```powershell
./venv_kedro/Scripts/Activate.ps1
kedro run --pipeline reduccion_dimensional
kedro run --pipeline kmeans
dvc repro kmeans_run
```

---
## ğŸ§ª Extensiones Futuras
- AÃ±adir UMAP como alternativa a tâ€‘SNE.
- Elipses de confianza en plot GMM.
- Export de mÃ©tricas a JSON para `dvc metrics show`.
